---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I will soon enroll in a PhD program at The Hong Kong University of Science and Technology (Guangzhou) as a 25fall candidate, having already completed my undergraduate studies.

I am now working on Generative models(T2I, T2M, T2W, Radio Map Generation), XAI research. If you would like to have an academic discussion or cooperation, please feel free to email me at chatoncws@gmail.com.

My research interests include:

- AIGC(Text-to-Motion Generation, Unified Model)
- XAI



# üî• News
- *2025.07* Three paper are accepted by **ACM MM BNI Track 2025 (Oral)**. Congratulations to the collaborators!
- *2025.07* Three paper are accepted by **ACM MM 2025**. Congratulations to the collaborators!
- *2025.06* One paper  is accepted by **Automation in Construction (Q1, IF 11.5)**. Congratulations to the collaborators!
- *2025.05* One paper of t2i is accepted by **ICML 2025**. Congratulations to the collaborators!
- *2024.10* I will join Hong Kong University of Science and Technology (Guangzhou) as a PhD student in Fall 2025, supervised by Associate Professor [Yutao Yue](https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/YUE-Yutao/yutaoyue).
- *2024.09* One paper of XAI is accepted by **NeurIPS 2024**. Congratulations to the collaborators!
- *2024.09* I join CUHK(shenzhen) as a RA supervised by Professor [Zhizheng Wu](https://drwuz.com/).
- *2024.07* One paper of robustness of text-to-motion generation is accepted by **ACM MM 2024**. Congratulations to the collaborators!
- *2023.12*: I am a remote intern supervised by Professor [Di Wang](https://shao3wangdi.github.io/).
- *2023.08*: I am a remote intern supervised by Professor [Chen Chen](https://www.crcv.ucf.edu/chenchen/).
- *2023.06*: I join Agibot as a reasearch intern.

# üìù Publications 

## **2025**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2025</div><img src='images/ant.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**[ANT: Adaptive Neural Temporal-Aware Text-to-Motion Model](https://arxiv.org/pdf/2506.02452)**

**Wenshuo Chen#**, Kuimou Yu#, Haozhe Jia#, Kaishen Yuan, Zexu Huang, Bowen Tian, Songning Lai, Hongru Xiao, Erhang Zhang, Lei Wang, Yutao Yue

[**Code**](https://github.com/CCSCovenant/ANT) 

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM BNI 2025 (Oral)</div><img src='images/RMDM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
**[RMDM: Radio Map Diffusion Model with Physics Informed](https://arxiv.org/abs/2501.19160)**
  
Haozhe Jia#, **Wenshuo Chen#**, Zhihui Huang#, Hongru Xiao, Nanqian Jia, Keming Wu, Songning Lai, Yutao Yue

[**Code**](https://github.com/Hxxxz0/RMDM) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2025</div><img src='images/dct_diff.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
**[DCTdiff: Intriguing Properties of Image Generative Modeling in the DCT Space](https://arxiv.org/abs/2412.15032)**

Mang Ning, Mingxiao Li, Jianlin Su, Jia Haozhe, Lanmiao Liu, Martin Benes, **Wenshuo Chen**, Albert Ali Salah, Itir Onal Ertugrul 

[**Code**](https://github.com/forever208/DCTdiff) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2025</div><img src='images/t2w.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
**[Text2Weight: Bridging Natural Language and Neural Network Weight Spaces](https://arxiv.org/abs/2508.13633)**

Bowen Tian#, **Wenshuo Chen#**, Zexi Li, Songning Lai, Jiemin Wu, Yutao Yue


[**Code**](https://github.com/TianSuya/T2W) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2025</div><img src='images/time_pre.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**[From Guesswork to Guarantee: Towards Faithful Multimedia Web Forecasting with TimeSieve](https://arxiv.org/pdf/2405.19647)**
  
Songning Lai, Ninghui Feng, Jiechao Gao, Hao Wang, Haochen Sui, Xin Zou, Jiayu Yang, **Wenshuo Chen**, Lijie Hu, Hang Zhao, Xuming Hu, Yutao Yue

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Automation in Construction</div><img src='images/ccs-tr.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
**[Automated detection of complex construction scenes using a lightweight transformer-based method](https://www.sciencedirect.com/science/article/pii/S092658052500370X)**
  
H Xiao, B Yang, Y Lu, **W Chen**, S Lai, B Gao

</div>
</div>

## 2024Âπ¥

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2024</div><img src='images/framework.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**[SATO: Stable Text-to-Motion Framework](https://arxiv.org/abs/2405.01461)**

**Wenshuo Chen#**, Hongru Xiao#, Erhang Zhang#, Lijie Hu, Lei Wang, Mengyuan Liu, Chen Chen

[**Project**](https://sato-team.github.io/Stable-Text-to-Motion-Framework/) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**Code**](https://github.com/sato-team/Stable-Text-to-Motion-Framework) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/framework_med.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
**[Towards Multi-dimensional Explanation Alignment for Medical Classification](https://arxiv.org/abs/2410.21494)**
  
Lijie Hu#, Songning Lai#, **Wenshuo Chen#**, Hongru Xiao, Hongbin Lin, Lu Yu, Jingfeng Zhang, and Di Wang
 
</div>
</div>

## Preprints

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/free-t2m.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">  
  
**[Free-T2M: Frequency Enhanced Text-to-Motion Diffusion Model
With Consistency Loss](https://arxiv.org/pdf/2501.18232)**
  
**Wenshuo Chen#**, Haozhe Jia#, Songning Lai, Keming Wu, Hongru Xiao, Lijie Hu, Yutao Yue

[**Code**](https://github.com/Hxxxz0/Free-T2m) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'>

</div>
</div>


# üéñ Honors and Awards
- *2023.10* National first prize in CUMCM-2023 **(Top 0.3%)**
- *2023.12* National Award for Intelligent Car 5G Communication Outdoor Competition 2023 **(Top 0.2%)**. 

# üìñ Educations
- *2021.09 - 2025.06*, Undergraduate Student, Shandong University, Qingdao. 





# üíª Internships
- *2024.09* I join CUHK(shenzhen) as a RA supervised by Professor [Zhizheng Wu](https://drwuz.com/).
- *2023.12*: I am a remote intern supervised by Professor [Di Wang](https://shao3wangdi.github.io/).
- *2023.08*: I am a remote intern supervised by Professor [Chen Chen](https://www.crcv.ucf.edu/chenchen/).
- *2023.06*: I join Agibot as a reasearch intern.
